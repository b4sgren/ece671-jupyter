{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 24.  Singular Value Decomposition\n",
    "Author: Brendon Forsgren (bforsgren29@gmail.com)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "Singualar Value Decomposition (SVD) is a matrix decomposition for any\n",
    "complex matrix that results in 2 unitary matrix and a diagonal matrix of\n",
    "singular values. SVD is a generalization of Eigenvalue Decomposition\n",
    "and is valid for any complex matrix, not just square matrices.\n",
    "\n",
    "SVD is one of the most important techniques of Linear Algebra \n",
    "(to the point that it could be called a power tool!) and for good reason.\n",
    "The SVD provides a robust solution to Least Squares and Min-Norm problems.\n",
    "Additionally it allows for a robust solution for ill conditioned problems\n",
    "(problems where the condition number of the A matrix is very high).\n",
    "Lastly, while many matrix decompositions have certain requirements about the matrix\n",
    "being decomposed (LU: square and full rank, Cholesky: square, full rank, and\n",
    "symetric positive definite, Eigenvalue Decomposition: Hermitian) SVD has no\n",
    "such requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the theory\n",
    "\n",
    "As mentioned above, SVD is a generalization of the $A=S\\Lambda S$ also known\n",
    "as the Eigenvalue Decomposition. The SVD extends this \n",
    "to be the following decomposition for any complex $m\\times n$ matrix:\n",
    "\n",
    "\\begin{align}\n",
    "A = U\\Sigma V^H\n",
    "\\end{align}\n",
    "\n",
    "where $U \\epsilon C^{m\\times m}$ and unitary, $V \\epsilon C^{n\\times n}$\n",
    "and unitary, and $\\Sigma \\epsilon R^{m \\times n}$ and diagonal.\n",
    "$\\Sigma$ is also filled with Singular Values $\\sigma_i$ such that \n",
    "$\\sigma_1 >= \\sigma_2 >= ... >= \\sigma_p >= 0$ where p = min(m, n). $\\Sigma$ is a rectangular\n",
    "matrix and as a result $\\Sigma$ is diagonal along the main diagonal with the\n",
    "remaining rows or columns being fille with zeros as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\Sigma = \\begin{pmatrix} \\sigma_1 & 0 & 0 & 0 \\\\ 0 & \\sigma_2 & 0 & 0 \\\\ 0 & 0 & \\sigma_3 & 0 \\end{pmatrix}\n",
    "or  \\Sigma = \\begin{pmatrix} \\sigma_1 & 0 & 0 \\\\ 0 & \\sigma_2 & 0 \\\\ 0 & 0 & \\sigma_3 \\\\ 0 & 0 & 0 \\end{pmatrix}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting property of the singular values in $\\Sigma$ is that they are the squareroot of the\n",
    "eigenvalues of $A^HA$ and $AA^H$ or $\\sigma_i = \\sqrt{\\lambda_i}$. This is shown by the following:\n",
    "\\begin{align}\n",
    "A^HA = V\\Sigma^H U^H U \\Sigma V^H\\\\\n",
    "A^HA = V\\Sigma^H I \\Sigma V^H\\\\\n",
    "A^HA = V\\Sigma^H \\Sigma V^H\\\\\n",
    "\\end{align}\n",
    "Let $\\Sigma^H \\Sigma = \\Lambda$\n",
    "\\begin{align}\n",
    "A^HA = V \\Lambda V^H\n",
    "\\end{align}\n",
    "Now multiplying each side on the right by V gives us\n",
    "\\begin{align}\n",
    "A^HAV = V \\Lambda\n",
    "\\end{align}\n",
    "Which is the definition of an eigenvalue. Therefore the eigenvalues ($\\Lambda$)\n",
    "of $A^HA$ are the square of the singular values ($\\Sigma$) of A.\n",
    "The same process can be repeated with the matrix $AA^H$ to obtain the same result\n",
    "Additionally it should be noted that in the case that A is a square matrix\n",
    "The SVD of A becomes equivalent to the Eigenvalue Decomposition and $\\sigma_i = \\lambda_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is convenient to use the following block matrix structure to write the SVD.\n",
    "\\begin{align}\n",
    "A = \\begin{pmatrix} U_1 & U_2 \\end{pmatrix} \\begin{pmatrix} \\Sigma_1 & 0 \\\\ 0 & \\Sigma_2 \\end{pmatrix} \\begin{pmatrix} V_1^H \\\\ V_2^H \\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Where $U_1 \\epsilon C^{m\\times r}$, $U_2 \\epsilon C^{m \\times (m-r)}$,\n",
    "$V_1^H \\epsilon C^{r \\times n}$, $V_2^H \\epsilon C^{(n-r) \\times n}$,\n",
    "$\\Sigma_1 = diag(\\sigma_1, ... , \\sigma_r)$ of size $r\\times r$ and\n",
    "$\\Sigma_2$ is a diagonal matrix of size $(m-r) \\times (m-r)$ and $\\sigma_i = 0$.\n",
    "This allows A to be written in the following format in terms of the non-zero singular values.\n",
    "\\begin{align}\n",
    "\\\\\n",
    "A = U_1 \\Sigma_1 V_1^H = \\Sigma_{i=1}^r \\sigma_i u_i v_i^H\n",
    "\\end{align}\n",
    "\n",
    "This will be useful when finding solutions to equations in the form Ax=b when\n",
    "A is rank deficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Numerical Examples\n",
    "\n",
    "As mentioned above the SVD has numerous applications to solving the problem $Sx = b$.\n",
    "In this section I will show some examples of how the matrix rank relates to the SVD,\n",
    "how to find the pseudo-inverse of matrix A using the SVD, and how to solve poorly conditioned problems using SVD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example deals with the rank of matrix A. Simply put the rank of A is\n",
    "equal to the number of non-zeros singular values (the rank of $\\Sigma$).\n",
    "This can simply be shown using the following proof: \n",
    "\\begin{align}\n",
    "A = U \\Sigma V^H\\\\\n",
    "rank(A) = rank(U \\Sigma V^H)\\\\\n",
    "\\end{align}\n",
    "Since U and $V^H$ are unitary they do not affect the rank of $\\Sigma$.Therefore \n",
    "\\begin{align}\n",
    "rank(A) = rank(\\Sigma)\n",
    "\\end{align}\n",
    "The following python codes illustrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A:', array([[  5,   0,  -9,  -2,   7],\n",
      "       [ -5,   0,  -1,   0,   5],\n",
      "       [ -7,  -7,  -5,   9, -10],\n",
      "       [ -7,  -2,   3,   2,   9]]))\n",
      "('The numer of non-zero singular values in A is:', 4)\n",
      "('The rank of A is:', 4)\n",
      "('B:', array([[  2. ,   7. ,  -7. ,   4. , -15. ],\n",
      "       [ 12. ,   2. ,  -3. , -17. ,   6. ],\n",
      "       [  4. ,  14. , -14. ,   8. , -30. ],\n",
      "       [ 36. ,   6. ,  -9. , -51. ,  18. ],\n",
      "       [  1. ,   3.5,  -3.5,   2. ,  -7.5]]))\n",
      "('The numer of non-zero singular values in B is:', 2)\n",
      "('The rank of B is:', 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as spl\n",
    "import numpy.linalg as npl\n",
    "\n",
    "def checkSingularValues(s):\n",
    "    s[s<1e-10] = 0\n",
    "    return s\n",
    "\n",
    "# For a random matrix\n",
    "A = np.random.randint(-10, 10, size=(4, 5))\n",
    "U, s, Vh = spl.svd(A)\n",
    "s = checkSingularValues(s)\n",
    "print('A:', A)\n",
    "print('The numer of non-zero singular values in A is:', np.count_nonzero(s))\n",
    "print('The rank of A is:', npl.matrix_rank(A))\n",
    "\n",
    "# For a rank deficient matrix\n",
    "B = np.array([[2, 7, -7, 4, -15], [12, 2, -3, -17, 6], [4, 14, -14, 8, -30], [36, 6, -9, -51, 18], [1, 3.5, -3.5, 2, -7.5]])\n",
    "U, s, Vh = spl.svd(B)\n",
    "print('B:', B)\n",
    "s = checkSingularValues(s)\n",
    "print('The numer of non-zero singular values in B is:', np.count_nonzero(s))\n",
    "print('The rank of B is:', npl.matrix_rank(B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next example will show how to compute the pseudo inverse using SVD.\n",
    "This can be done for both full rank and rank deficient matrices.\n",
    "The following derivation shows how to find the pseudo inverse for a full rank, tall matrix.\n",
    "\\begin{align}\n",
    "A = \\begin{pmatrix} U_1 & U_2 \\end{pmatrix} \\begin{pmatrix} \\Sigma_1 \\\\ 0 \\end{pmatrix} V^H = U_1 \\Sigma_1 V^H\\\\\n",
    "(A^HA)^{-1}A^H = (V \\Sigma_1 U_1^H U_1 \\Sigma_1 V^H)^{-1}V \\Sigma_1 U^H\\\\\n",
    "(A^HA)^{-1}A^H = (V \\Sigma_1 \\Sigma_1 V^H)^{-1}V \\Sigma_1 U^H\\\\\n",
    "(A^HA)^{-1}A^H = V \\Sigma_1^{-1} \\Sigma_1^{-1} V^H V \\Sigma_1 U^H\\\\\n",
    "(A^HA)^{-1}A^H = V \\Sigma_1^{-1} U^H\\\\\n",
    "Where \\Sigma_1^{-1} = diag(1/\\sigma_1, 1/\\sigma_2,..., 1/\\sigma_r)\n",
    "\\end{align}\n",
    "To extend this to a rank deficient matrix simply get rid of all the singular values equal to 0\n",
    "and the columns in $U$ and rows in $V^H$ corresponding to those values.\n",
    "The following code has and example finding the pseudo inverse for a tall matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_svd:', array([-0.26666667,  4.2       , -2.93333333]))\n",
      "('x:', array([-0.26666667,  4.2       , -2.93333333]))\n"
     ]
    }
   ],
   "source": [
    "def invertSingularValues(s):\n",
    "    index = np.nonzero(s)\n",
    "    s[index] = 1.0/s[index]\n",
    "    return s\n",
    "\n",
    "# Tall matrix case\n",
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [2, 6, 5]])\n",
    "b = np.array([3, -5, 9, 10]).T\n",
    "U, s, Vh = spl.svd(A)\n",
    "\n",
    "s = checkSingularValues(s)\n",
    "s = invertSingularValues(s)\n",
    "\n",
    "S = np.diag(s)\n",
    "S = np.hstack((S, np.zeros((3, 1))))\n",
    "SVD_inv = np.dot(np.dot(Vh.T, S), U.T)\n",
    "x_svd = np.dot(SVD_inv, b)\n",
    "\n",
    "A_inv = npl.pinv(A)\n",
    "x = np.dot(A_inv, b)\n",
    "print('x_svd:', x_svd)\n",
    "print('x:', x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is for a fat matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_svd:', array([ 0.94444444, -0.05555556,  0.61111111, -0.16666667]))\n",
      "('x:', array([ 0.94444444, -0.05555556,  0.61111111, -0.16666667]))\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3, 4], [5, 4, 3, 2], [-1, 6, -2, 3]])\n",
    "b = np.array([2, 6, -3]).T\n",
    "U, s, Vh = spl.svd(A)\n",
    "\n",
    "s = checkSingularValues(s)\n",
    "s = invertSingularValues(s)\n",
    "\n",
    "S = np.diag(s)\n",
    "S = np.vstack((S, np.zeros((1, 3))))\n",
    "svd_inv = np.dot(np.dot(Vh.T, S), U.T)\n",
    "x_svd = np.dot(svd_inv, b)\n",
    "\n",
    "A_inv = npl.pinv(A)\n",
    "x = np.dot(A_inv, b)\n",
    "print('x_svd:', x_svd)\n",
    "print('x:', x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is for a rank deficient matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('U1*S1*V1h:', array([[1., 2., 3.],\n",
      "       [4., 5., 6.],\n",
      "       [7., 8., 9.],\n",
      "       [2., 4., 6.]]))\n",
      "('x_svd:', array([-1.67521368,  0.04273504,  1.76068376]))\n",
      "('x:', array([-1.67521368,  0.04273504,  1.76068376]))\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [2, 4, 6]])\n",
    "r = npl.matrix_rank(A)\n",
    "b = np.array([3, -5, 9, 10]).T\n",
    "U, s, Vh = spl.svd(A)\n",
    "\n",
    "s = checkSingularValues(s)\n",
    "\n",
    "S = np.diag(s)\n",
    "U1 = U[:, 0:r]\n",
    "S1 = S[0:r, 0:r]\n",
    "V1h = Vh[0:r, :]\n",
    "\n",
    "print('U1*S1*V1h:', np.dot(np.dot(U1, S1), V1h))\n",
    "S1 = npl.inv(S1)\n",
    "svd_inv = np.dot(np.dot(V1h.T, S1), U1.T)\n",
    "x_svd = np.dot(svd_inv, b)\n",
    "\n",
    "x = np.dot(npl.pinv(A), b)\n",
    "print('x_svd:', x_svd)\n",
    "print('x:', x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
     "As can be seen for the 3 examples above, the SVD provides a robust means of\n",
     "finding the pseudo inverse of a matrix in order to solve least squares, and min-norm problems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will discuss how the SVD can be used to solve poorly conditioned problems.\n",
    "A matrix is poorly conditioned when two of the rows in the matrix become almost parallel.\n",
    "The sigular values in the SVD identify the direction of in which the problem is\n",
    "poorly conditioned. The direction of sensitivity are identified by very small singular values.\n",
    "Therefore, to better condition a problem all that we need to do is identify very small singular values\n",
    "and discard them by setting them equal to 0. The follow code illustrates how this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('K(A): ', 3.224405992534971e+16)\n",
      "('s: ', array([9.62347538e+00, 6.23475383e-01, 2.98457310e-16]))\n",
      "('x1_b1: ', array([ 1.67528147e+15, -3.35056294e+15,  1.67528147e+15]))\n",
      "('x1_b2: ', array([ 1.19503411e+15, -2.39006823e+15,  1.19503411e+15]))\n",
      "('x2_b1: ', array([ 83., 122., 161.]))\n",
      "('x2_b2: ', array([ 84.34, 123.81, 163.28]))\n",
      "('x3_b1: ', array([0.90807556, 1.31937423, 1.73067291]))\n",
      "('x3_b2: ', array([0.92139029, 1.33871967, 1.75604904]))\n",
      "('x_b1:', array([-1.91666667,  0.83333333,  3.58333333]))\n",
      "('x_b2:', array([-1.62833333,  0.9       ,  3.42833333]))\n"
     ]
    }
   ],
   "source": [
    "def checkSingularValues(s, val):\n",
    "    s[s<val] = 0\n",
    "    return s\n",
    "\n",
    "A = np.array([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\n",
    "print('K(A): ', npl.cond(A))\n",
    "b1 = np.array([10, 14, 15]).T\n",
    "b2 = b1 + np.array([.1, -.13, 0.5]).T\n",
    "\n",
    "U, s, Vh = spl.svd(A)\n",
    "print('s: ', s)\n",
    "\n",
    "# Keeping all of the singular values\n",
    "s1 = invertSingularValues(s)\n",
    "S = np.diag(s1)\n",
    "temp = np.dot(np.dot(Vh.T, S), U.T)\n",
    "x1_b1 = np.dot(temp, b1)\n",
    "x1_b2 = np.dot(temp, b2)\n",
    "print('x1_b1: ', x1_b1)\n",
    "print('x1_b2: ', x1_b2)\n",
    "\n",
    "# Removing singular values less than 1e-10\n",
    "s2 = checkSingularValues(s, 1e-10)\n",
    "s2 = invertSingularValues(s2)\n",
    "S = np.diag(s2)\n",
    "temp = np.dot(np.dot(Vh.T, S), U.T)\n",
    "x2_b1 = np.dot(temp, b1)\n",
    "x2_b2 = np.dot(temp, b2)\n",
    "print('x2_b1: ', x2_b1)\n",
    "print('x2_b2: ', x2_b2)\n",
    "\n",
    "# Remove all singular values less than 1\n",
    "s3 = checkSingularValues(s, 1)\n",
    "s3 = invertSingularValues(s3)\n",
    "S = np.diag(s3)\n",
    "temp = np.dot(np.dot(Vh.T, S), U.T)\n",
    "x3_b1 = np.dot(temp, b1)\n",
    "x3_b2 = np.dot(temp, b2)\n",
    "print('x3_b1: ', x3_b1)\n",
    "print('x3_b2: ', x3_b2)\n",
    "\n",
    "# Compare with pinv\n",
    "A_inv = npl.pinv(A)\n",
    "print('x_pinv_b1:', np.dot(A_inv, b1))\n",
    "print('x_pinv_b2:', np.dot(A_inv, b2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen removing the small singular values gives a more robust solution\n",
    "meaning that for small changes in the b, there are small changes in x.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Engineering Application\n",
    "\n",
    "Provide a more sophisticated example showing one engineering example of the topic, complete with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
