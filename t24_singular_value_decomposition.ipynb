{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 24.  Singular Value Decomposition\n",
    "Author: Brendon Forsgren (bforsgren29@gmail.com)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Introduction\n",
    "Singualar Value Decomposition (SVD) is a matrix decomposition for any\n",
    "complex matrix that results in 2 unitary matrix and a diagonal matrix of\n",
    "singular values. SVD is a generalization of Eigenvalue Decomposition\n",
    "and is valid for any complex matrix, not just square matrices.\n",
    "\n",
    "SVD is one of the most important techniques of Linear Algebra \n",
    "(to the point that it could be called a power tool!) and for good reason.\n",
    "The SVD provides a robust solution to Least Squares and Min-Norm problems.\n",
    "Additionally it allows for a robust solution for ill conditioned problems\n",
    "(problems where the condition number of the A matrix is very high).\n",
    "Lastly, while many matrix decompositions have certain requirements about the matrix\n",
    "being decomposed (LU: square and full rank, Cholesky: square, full rank, and\n",
    "symetric positive definite, Eigenvalue Decomposition: Hermitian) SVD has no\n",
    "such requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the theory\n",
    "\n",
    "As mentioned above, SVD is a generalization of the $A=S\\Lambda S$ also known\n",
    "as the Eigenvalue Decomposition. The SVD extends this \n",
    "to be the following decomposition for any complex $m\\times n$ matrix:\n",
    "\n",
    "\\begin{align}\n",
    "A = U\\Sigma V^H\n",
    "\\end{align}\n",
    "\n",
    "where $U \\epsilon C^{m\\times m}$ and unitary, $V \\epsilon C^{n\\times n}$\n",
    "and unitary, and $\\Sigma \\epsilon R^{m \\times n}$ and diagonal.\n",
    "$\\Sigma$ is also filled with Singular Values $\\sigma_i$ such that \n",
    "$\\sigma_1 >= \\sigma_2 >= ... >= \\sigma_p >= 0$ where p = min(m, n). $\\Sigma$ is a rectangular\n",
    "matrix and as a result $\\Sigma$ is diagonal along the main diagonal with the\n",
    "remaining rows or columns being fille with zeros as shown below."
   ]
  },
  {
    "cell_type": "markdown",
    "metadata":{},
    "source": [
      "\\begin{align}\n",
      "\\Sigma = \\begin{pmatrix} \\sigma_1 & 0 & 0 & 0 \\\\ 0 & \\sigma_2 & 0 & 0 \\\\ 0 & 0 & \\sigma_3 & 0 \\end{pmatrix}\n",
      "or  \\Sigma = \\begin{pmatrix} \\sigma_1 & 0 & 0 \\\\ 0 & \\sigma_2 & 0 \\\\ 0 & 0 & \\sigma_3 \\\\ 0 & 0 & 0 \\end{pmatrix}\n",
      "\\end{align}\n"
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "An interesting property of the singular values in $\\Sigma$ is that they are the squareroot of the\n",
      "eigenvalues of $A^HA$ and $AA^H$ or $\\sigma_i = \\sqrt{\\lambda_i}$. This is shown by the following:\n",
      "\\begin{align}\n",
      "A^HA = V\\Sigma^H U^H U \\Sigma V^H\\\\\n",
      "A^HA = V\\Sigma^H I \\Sigma V^H\\\\\n",
      "A^HA = V\\Sigma^H \\Sigma V^H\\\\\n",
      "\\end{align}\n",
      "Let $\\Sigma^H \\Sigma = \\Lambda$\n",
      "\\begin{align}\n",
      "A^HA = V \\Lambda V^H\n",
      "\\end{align}\n",
      "Now multiplying each side on the right by V gives us\n",
      "\\begin{align}\n",
      "A^HAV = V \\Lambda\n",
      "\\end{align}\n",
      "Which is the definition of an eigenvalue. Therefore the eigenvalues ($\\Lambda$)\n",
      "of $A^HA$ are the square of the singular values ($\\Sigma$) of A.\n",
      "The same process can be repeated with the matrix $AA^H$ to obtain the same result\n",
      "Additionally it should be noted that in the case that A is a square matrix\n",
      "The SVD of A becomes equivalent to the Eigenvalue Decomposition and $\\sigma_i = \\lambda_i$."
    ]
  },
  {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
      "Often it is convenient to use the following block matrix structure to write the SVD.\n",
      "\\begin{align}\n",
      "A = \\begin{pmatrix} U_1 & U_2 \\end{pmatrix} \\begin{pmatrix} \\Sigma_1 & 0 \\\\ 0 & \\Sigma_2 \\end{pmatrix} \\begin{pmatrix} V_1^H \\\\ V_2^H \\end{pmatrix}\n",
      "\\end{align}\n",
      "\n",
      "Where $U_1 \\epsilon C^{m\\times r}$, $U_2 \\epsilon C^{m \\times (m-r)}$,\n",
      "$V_1^H \\epsilon C^{n \\times r}$, $V_2^H \\epsilon C^{n \\times (n-r)}$,\n",
      "$\\Sigma_1 = diag(\\sigma_1, ... , \\sigma_r)$ of size $r\\times r$ and\n",
      "$\\Sigma_2$ is a diagonal matrix of size $(m-r) \\times (m-r)$ and $\\sigma_i = 0$.\n",
      "This allows A to be written in the following format in terms of the non-zero singular values.\n",
      "\\begin{align}\n",
      "\\\\\n",
      "A = U_1 \\Sigma_1 V_1^H = \\Sigma_{i=1}^r \\sigma_i u_i v_i^H\n",
      "\\end{align}\n",
      "\n",
      "This will be useful when finding solutions to equations in the form Ax=b when\n",
      "A is rank deficient."
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Numerical Examples\n",
    "\n",
    "Provide some simple python code and examples that emphasize the basic concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Engineering Application\n",
    "\n",
    "Provide a more sophisticated example showing one engineering example of the topic, complete with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
